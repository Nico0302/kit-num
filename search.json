[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Vorlesungsnotizen zu Numerik für Informatiker",
    "section": "",
    "text": "Einführung\nEs handelt sich hierbei um meine Vorlesungsnotizen, basierend auf den Übungsaufzeichnungen, dem offiziellen Skript (Wieners 2025), sowie Passagen aus Bartels (2016).\n\n\n\n\n\n\nVorsicht\n\n\n\nDie Notizen sind nicht vollständig und dienen lediglich als Ergänzung zu den Vorlesungsunterlagen.\nSolltest du einen Fehler finden, kannst du ein Issue anlegen.\n\n\n\n\n\n\nBartels, Sören. 2016. Numerik 3x9: Drei Themengebiete in jeweils neun kurzen Kapiteln. 1. Aufl. 2016. Springer-Lehrbuch. Berlin Heidelberg: Springer Spektrum. https://doi.org/10.1007/978-3-662-48203-2.\n\n\nWieners, Christian. 2025. „Einführung in Die Numerische Mathematik“.",
    "crumbs": [
      "Einführung"
    ]
  },
  {
    "objectID": "01-arithmetik.html",
    "href": "01-arithmetik.html",
    "title": "1  Arithmetik",
    "section": "",
    "text": "1.1 Gleitkommazahlen\nWir betrachten für eine gegebene Basis \\(B \\geq 2\\), einen minimalen Exponent \\(E^{-}\\) und Längen \\(M\\) und \\(E\\) die endliche Menge der normalisierten Gleitpunktzahlen \\(\\mathrm{FL}\\).\n\\[\n\\mathrm{FL}:=\\{ \\pm B^e \\underbrace{\\sum_{l=1}^M a_l B^{-l}}_{=m} \\; | \\; e=E^{-}+\\sum_{k=0}^{E-1} c_k B^k, \\  a_l, c_k \\in\\{0, \\ldots, B-1\\}, \\ a_1 \\neq 0\\} \\cup\\{0\\}\n\\]\nMaschienengenauigkeit\n\\[\n\\text{eps} := \\sup \\left\\{ \\frac{|x - fl(x)|}{|x|} \\ | \\ 1 &lt; x &lt; 2 \\right\\} = \\frac{B^{1-M}}{2}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Arithmetik</span>"
    ]
  },
  {
    "objectID": "01-arithmetik.html#auslöschung",
    "href": "01-arithmetik.html#auslöschung",
    "title": "1  Arithmetik",
    "section": "1.2 Auslöschung",
    "text": "1.2 Auslöschung\n\nN = 2**10\n\ndef exp(x):\n    \"\"\"\n    Compute the exponential function using Taylor series expansion.\n    \"\"\"\n    return np.sum([x**n / math.factorial(n) for n in range(N)], axis=0)\n\nx = 10\n\nz_bad = exp(-x)\nz_good = 1 / exp(x)\n\nr = np.exp(-x) # reference\n\nnp.abs(z_bad - r) / r, np.abs(z_good - r) / r\n\n(np.float64(6.529424994681785e-09), np.float64(1.4925713791816933e-16))\n\n\nQuadratische Gleichung\nAnstatt \\(x_2=p-\\sqrt{p^2-q}\\), verwenden wir\n\\[\nx_2=p-\\sqrt{p^2-q} \\cdot \\frac{p+\\sqrt{p^2+q}}{p+\\sqrt{p^2+q}} = \\frac{q}{p+\\sqrt{p^2-q}}=\\frac{q}{x_1}\n\\]\n(Satz von Vieta) um die Auslöschung zwischen \\(p\\) und \\(\\sqrt{p^2-q}\\) zu vermeiden.\n\np = 1e10\nq = 1e2\n\nprint(np.roots([1, -2*p, q])) # reference\n\nx1 = p + math.sqrt(p**2 - q)\n\nx2_bad = p - math.sqrt(p**2 - q)\nx2_good = q / x1\n\nx2_bad, x2_good\n\n[2.e+10 5.e-09]\n\n\n(0.0, 5e-09)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Arithmetik</span>"
    ]
  },
  {
    "objectID": "01-arithmetik.html#kondition-und-stabilität",
    "href": "01-arithmetik.html#kondition-und-stabilität",
    "title": "1  Arithmetik",
    "section": "1.3 Kondition und Stabilität",
    "text": "1.3 Kondition und Stabilität\n\nDie Kondition eines Problems ist ein Maß dafür, wie stark die Abhängigkeit der Lösung von den Daten ist.\nAbsolute Konditionszahl\n\\[\n\\kappa_\\text{abs}(x) = | f'(x) |\n\\]\nRelative Konditionszahl\n\\[\n\\kappa_\\text{rel}(x) = \\frac{| f'(x) |}{|f(x)|} \\cdot |x|\n\\]\nMatrix Kondition\n\\[\n\\kappa_p(A) = ||A||_p \\cdot ||A^{-1}||_p \\quad \\text{für } p = 1,2,\\infty\n\\]\n\n\n\n\n\n\nHinweis\n\n\n\nFür symmetrische Matrizen (\\(A=A^\\top\\)) gilt:\n\n\\(\\sigma(A) \\subset \\mathbb{R}\\) (Spektrum bzw. alle Eigenwerte sind reell)\n\\(\\|A\\|_2=\\rho(A)\\) (Septralradius bzw. größter Eigenwert im Betrag)\n\\(\\kappa_2(A)=\\frac{\\max _{\\lambda \\in \\sigma(A)}|\\lambda|}{\\min _{\\lambda \\in \\sigma(A)}|\\lambda|}\\) (Verhältnis der größten zur kleinsten Eigenwerte im Betrag)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Arithmetik</span>"
    ]
  },
  {
    "objectID": "01-arithmetik.html#vektor--und-matrixnormen",
    "href": "01-arithmetik.html#vektor--und-matrixnormen",
    "title": "1  Arithmetik",
    "section": "1.4 Vektor- und Matrixnormen",
    "text": "1.4 Vektor- und Matrixnormen\nDefinition 2.1 Eine Norm auf \\(\\mathbb{R}^n\\) ist eine Abbildung \\(\\|\\cdot\\|: \\mathbb{R}^n \\rightarrow \\mathbb{R}_{\\geq 0}\\) mit den folgenden Eigenschaften:\n\n\\(\\|x\\|=0 \\Longrightarrow x=0\\) für alle \\(x \\in \\mathbb{R}^n\\) (Definitheit);\n\\(\\|x+y\\| \\leq\\|x\\|+\\|y\\|\\) für alle \\(x, y \\in \\mathbb{R}^n\\) (Dreiecksungleichung);\n\\(\\|\\lambda x\\|=|\\lambda|\\|x\\|\\) für alle \\(\\lambda \\in \\mathbb{R}\\) und \\(x \\in \\mathbb{R}^n\\) (Homogenität).\n\nWir verwenden für \\(x \\in \\mathbb{R}^N\\) und \\(A \\in \\mathbb{R}^{M \\times N}\\)\n\\[\n\\begin{array}{ll}\n|x|_1=\\sum_{n=1}^N\\left|x_n\\right| & \\text { 1-Norm } \\\\\n|x|_2=\\sqrt{x^T x}=\\left(\\sum_{n=1}^N\\left|x_n\\right|^2\\right)^{\\frac{1}{2}} & \\text { Euklidische Norm } \\\\\n|x|_{\\infty}=\\max _{n=1, \\ldots, N}\\left|x_n\\right| & \\text { Supremumsnorm }\n\\end{array}\n\\]\nFür Matrizen \\(A \\in \\mathbb{R}^{M \\times N}\\) definieren wir eine allgemeine Norm mit:\n\\[\\|A\\|_{o p}=\\sup _{x \\in \\mathbb{R}^n,\\|x\\|=1}\\|A x\\|=\\inf \\left\\{c \\geq 0: \\forall x \\in \\mathbb{R}^n\\|A x\\| \\leq c\\|x\\|\\right\\}\\]\n\\[\n\\begin{array}{ll}\n\\|A\\|_1=\\max _{n=1, \\ldots, N} \\sum_{m=1}^M|A[m, n]| & \\text { Spaltensummennorm, } \\\\\n\\|A\\|_2=\\sqrt{\\rho\\left(A^T A\\right)} & \\text { Spektralnorm, } \\\\\n\\|A\\|_{\\infty}=\\max _{m=1, \\ldots, M} \\sum_{n=1}^N|A[m, n]| & \\text { Zeilensummennorm, } \\\\\n\\|A\\|_F=\\left(\\sum_{m=1}^M \\sum_{n=1}^N A[m, n]^2\\right)^{\\frac{1}{2}} & \\text { Frobeniusnorm. }\n\\end{array}\n\\]\nDabei ist\n\\[\n\\begin{aligned}\n& \\rho(A)=\\max \\{|\\lambda|: \\lambda \\in \\sigma(A)\\}  \\text { Spektralradius, }  \\\\\n& \\sigma(A)=\\left\\{\\lambda \\in \\mathbb{C}: \\operatorname{det}\\left(A-\\lambda I_N\\right)=0\\right\\}  \\text { Spektrum. }\n\\end{aligned}\n\\]\nEs gilt immer\n\\[|A x|_p \\leq\\|A\\|_p|x|_p\\]\nfür alle \\(x \\in \\mathbb{R}^N\\) und wegen \\(\\|A\\|_2 \\leq\\|A\\|_F\\) auch\n\\[\n|A x|_2 \\leq\\|A\\|_2|x|_2 \\leq\\|A\\|_F|x|_2\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Arithmetik</span>"
    ]
  },
  {
    "objectID": "02-lgs.html",
    "href": "02-lgs.html",
    "title": "2  Direkte Lösungsverfahren für lineare Gleichungen",
    "section": "",
    "text": "2.1 Vorwärts-Substitution\n\\[\nL = \\begin{pmatrix}\n1      \\\\\nl_{21} & 1      \\\\\nl_{31} & l_{32} & 1      \\\\\n\\vdots & \\vdots & \\vdots & \\ddots \\\\\nl_{n1} & l_{n2} & l_{n3} & \\dots  & 1 \\\\\n\\end{pmatrix}\n\\]\nDie Vorwärts-Substitution löst \\(L\\cdot\\mathbf{y}=\\mathbf{b}\\) (normierte untere Dreiecksmatrix), indem wir über die Zeilen iterieren und dabei die Lösungen der vorheringen \\(\\mathbf{x}_j\\) für die Berechung des aktuellen \\(\\mathbf{x}_i\\) verwenden (\\(\\mathbf{x}_1 = \\mathbf{b}_1\\)).\nDie Laufzeit liegt somit in \\(O(n^2)\\).\ndef forward_sub(lower, rhs):\n    n = lower.shape[0]\n    solution = np.zeros(n)\n    for i in range(n):\n        solution[i] = rhs[i]\n        for j in range(i):\n            solution[i] -= lower[i, j] * solution[j]\n            solution[i] = solution[i] / lower[i, i]\n    return solution\nforward_sub(np.array([\n    [1, 0, 0], \n    [2, 1, 0], \n    [3, 4, 1]]\n), np.array([1, 2, 3]))\n\narray([1., 0., 0.])",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Direkte Lösungsverfahren für lineare Gleichungen</span>"
    ]
  },
  {
    "objectID": "02-lgs.html#rückwärts-substitution",
    "href": "02-lgs.html#rückwärts-substitution",
    "title": "2  Direkte Lösungsverfahren für lineare Gleichungen",
    "section": "2.2 Rückwärts-Substitution",
    "text": "2.2 Rückwärts-Substitution\n\\[\nR = \\begin{pmatrix}\nr_{11} & r_{12} & r_{13} & \\dots  & r_{1n} \\\\\n    & r_{22} & r_{23} & \\dots  & r_{2n} \\\\\n    &        & r_{33} & \\dots  & r_{3n} \\\\\n    &        &        & \\ddots & \\vdots \\\\\n    &        &        &        & r_{nn}\n\\end{pmatrix}\n\\]\nDie Rückwärts-Substitution löst \\(R \\cdot \\mathbf{x}=\\mathbf{y}\\), indem wir von der letzten Zeile aus das verfahren der Vorwärts-Substitution anwenden.\nDie Laufzeit liegt somit ebenfalls in \\(O(n^2)\\).\n\ndef backward_sub(upper, rhs):\n    n = upper.shape[0]\n    solution = np.zeros(n)\n    for i in range(n - 1, -1, -1):\n        tmp = rhs[i]\n        for j in range(i + 1, n):\n            tmp -= upper[i, j] * solution[j]\n            solution[i] = tmp / upper[i, i]\n    return solution\n\n\nbackward_sub(np.array([\n    [2, 2, 3], \n    [0, 1, 4], \n    [0, 0, 1]]\n), np.array([1, 0, 0]))\n\narray([0.5, 0. , 0. ])",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Direkte Lösungsverfahren für lineare Gleichungen</span>"
    ]
  },
  {
    "objectID": "02-lgs.html#lr-zerlegung",
    "href": "02-lgs.html#lr-zerlegung",
    "title": "2  Direkte Lösungsverfahren für lineare Gleichungen",
    "section": "2.3 LR-Zerlegung",
    "text": "2.3 LR-Zerlegung\n(en. LU-Decomposition)\n\n\n\n\n\n\n\nWarnung\n\n\n\nDie \\(1\\)-en auf der Diagonalen der \\(L\\)-Matrix bleiben beim Zeilentauschen unverändert\n\n\nDie \\(LR\\)-Zerlegung lässt sich mittels des Gauß-Algorithmus bestimmen, indem wir \\(A\\) auf eine untere Dreiecksmatrix \\(R\\) gaußen und uns die Operationen in \\(L\\) “merken”. Sie ist eindeutig und benötigt \\(O(n^3)\\) Operationen.\nDie Berechnung ist nicht stabil.\nHinreichende Bedingungen für die Exsistenz einer \\(LR\\)-Zerlegung für eine quadratische Matrix \\(A\\):\n\nstrikt diagonal-dominant, daher das Diagonalelement ist größer als die Summe aller anderen Elemente in der Zeile, bzw.\n\n\\[\n|A[n, n]|&gt;\\sum_{\\substack{k=1 \\\\ k \\neq n}}^N|A[n, k]| \\quad \\text { für } n=1, \\ldots, N\n\\]\n\npositiv definit, daher alle Eigenwerte \\(&gt; 0\\), bzw.\n\n\\[\nx^{\\top} A x&gt;0 \\quad \\text { für alle } x \\in \\mathbb{R}^N, x \\neq 0 .\n\\]\n\n\n\n\n\n\nHinweis\n\n\n\n\n\n\nHauptminorenkriterium für positiv definite Matrizen\n\n\n\n\nFalls diese Bedingungen nicht gegeben sind, können wir mittels Zeilenvertauschung (Permutationsmatrix \\(P\\)) eine LR-zerlegbare Matrix \\(PA\\) in \\(O(n^3)\\) erzeugen.\n\ndef lu_decomposition(matrix):\n    n = matrix.shape[0]\n    lower = np.zeros(shape=matrix.shape)\n    upper = np.zeros(shape=matrix.shape)\n    for j in range(n):\n        lower[j][j] = 1.0\n        for i in range(j + 1):\n            first_sum = sum(upper[k][j] * lower[i][k] for k in range(i))\n            upper[i][j] = matrix[i][j] - first_sum\n        for i in range(j, n):\n            second_sum = sum(upper[k][j] * lower[i][k] for k in range(j))\n            lower[i][j] = (matrix[i][j] - second_sum) / upper[j][j]\n    return lower, upper\n\ndef solve_with_lu(matrix, rhs):\n    lower, upper = lu_decomposition(matrix)\n    y = forward_sub(lower, rhs)\n    return backward_sub(upper, y)\n\n\nmatrix = np.array([[2.0, 1.0],\n[1.0, 4.0]])\nrhs = np.array([1.0, 2.0])\nsolution = solve_with_lu(matrix, rhs)\nprint(\"solution\", solution)\ntest = rhs - np.dot(matrix, solution)\nprint(\"test \",test)\n\nsolution [0.5 0. ]\ntest  [0.  1.5]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Direkte Lösungsverfahren für lineare Gleichungen</span>"
    ]
  },
  {
    "objectID": "02-lgs.html#choelsky-zerlegung",
    "href": "02-lgs.html#choelsky-zerlegung",
    "title": "2  Direkte Lösungsverfahren für lineare Gleichungen",
    "section": "2.4 Choelsky-Zerlegung",
    "text": "2.4 Choelsky-Zerlegung\n\n\n\n\n\n\n(2.7) Satz\n\n\n\nSei \\(A \\in \\mathbb{R}^{N \\times N}\\) symmetrisch und positiv definit. Dann existiert genau eine Cholesky-Zerlegung \\(A=L L^{\\top}\\) mit einer regulären unteren Dreiecksmatrix \\(L\\).\n\n\nEs handelt sich somit um eine Spezialisierung der LR-Zerlegung für symmetrisch, positiv definite Matrizen.\n\\(\\renewcommand{\\b}[1]{\\color{teal}{#1}\\color{black}}\\renewcommand{\\o}[1]{\\color{orange}{#1}\\color{black}}\\)\n\\[\\begin{align}\nA &=\n\\begin{pmatrix}\n   a_{11} & a_{21} & a_{31}\\\\\n   a_{21} & a_{22} & a_{32}\\\\\n   a_{31} & a_{32} & a_{33}\\\\\n\\end{pmatrix}\\\\\n& =\n\\begin{pmatrix}\n   l_{11} & 0 & 0 \\\\\n   l_{21} & l_{22} & 0 \\\\\n   l_{31} & l_{32} & l_{33}\\\\\n\\end{pmatrix}\n\\begin{pmatrix}\n   l_{11} & l_{21} & l_{31} \\\\\n   0 & l_{22} & l_{32} \\\\\n   0 & 0 & l_{33}\n\\end{pmatrix} \\equiv L L^T \\\\\n&= \\begin{pmatrix}\n   l_{11}^2     & l_{21}l_{11} & l_{31}l_{11} \\\\\n   l_{21}l_{11} & l_{21}^2 + l_{22}^2& l_{31}l_{21}+l_{32}l_{22} \\\\\n   l_{31}l_{11} & l_{31}l_{21}+l_{32}l_{22} & l_{31}^2 + l_{32}^2+l_{33}^2\n\\end{pmatrix}\\end{align}\\]\n\n2.4.1 Berechnung\nDiagonalelemente:\n\\[l_{kk} = \\sqrt{a_{kk} - \\sum_{\\b{j}=1}^{k-1} l_{k\\b{j}}^2}\\]\nRest:\n\\[l_{\\o{i}k} = \\frac{1}{l_{kk}} \\left ( a_{ik} - \\sum_{\\b{j}=1}^{k-1} l_{\\o{i}\\b{j}}l_{k\\b{j}} \\right )\\]\n\ndef cholesky_decomposition(A):\n    n = matrix.shape[0]\n    lower = np.zeros(matrix.shape)\n    lower[0, 0] = np.sqrt(matrix[0, 0])\n    for n in range(1, n):\n        y = forward_sub(lower[:n, :n], matrix[n, :n]) # linalg.solve_triangular(lower[:n, :n], matrix[n, :n], lower=True)\n        lower[n, :n] = y\n        lower[n, n] = np.sqrt(matrix[n, n] - np.dot(y, y))\n    return lower\n\ndef solve_with_cholesky(matrix, rhs):\n    lower = cholesky_decomposition(matrix)\n    y = forward_sub(lower, rhs)\n    return backward_sub(lower.transpose(), y)\n\n\nmatrix = np.array([[2.0, 1.0],\n[1.0, 4.0]])\nrhs = np.array([1.0, 2.0])\nrhs = np.array([1.0, 2.0])\nsolution = solve_with_cholesky(matrix, rhs)\nprint(\"solution\",solution)\ntest = rhs - np.dot(matrix, solution)\nprint(\"test \",test)\n\nsolution [0.70710678 0.        ]\ntest  [-0.41421356  1.29289322]\n\n\n\nDie Cholesky-Zerlegung ist stabil: Es gilt \\(\\kappa_2(L)^2=\\kappa(A)\\)\nDie Berechnung der Cholesky-Zerlegung benötigt nur halbsoviele Operationen wie die Berechnung einer LR-Zerlegung.\nMatrizen mit einer geeigneten Hüllenstruktur (viele Nullelemente wie bei der Bandmatrix) können effizienter gelöst werden (Bandmatrix in \\(O(NM^2)\\))\n\n\n\n\nSchematische Darstellung einer Bandmatrix",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Direkte Lösungsverfahren für lineare Gleichungen</span>"
    ]
  },
  {
    "objectID": "02-lgs.html#qr-zerlegung",
    "href": "02-lgs.html#qr-zerlegung",
    "title": "2  Direkte Lösungsverfahren für lineare Gleichungen",
    "section": "2.5 QR-Zerlegung",
    "text": "2.5 QR-Zerlegung\n\n\n\n\n\n\n(2.14) Satz (QR-Zerlegung)\n\n\n\nZu \\(A \\in \\mathbb{R}^{M \\times N}\\) existiert eine \\(Q R\\)-Zerlegung \\(A=Q R\\) in eine orthogonale Matrix \\(Q \\in \\mathbb{R}^{M \\times M}\\) mit \\(Q^{\\top} Q=I_M\\) und eine obere Dreiecksmatrix \\(R \\in \\mathbb{R}^{M \\times N}\\) mit \\(R[m, n]=0\\) für \\(m&gt;n\\).\n\n\n\nDas LGS \\(Ax = b\\) kann durch die Berechnung \\(y = Q^\\top b\\) und darauf mit Rücksubstitution \\(Rx = y\\) gelöst werden.\nAsymptotischer Aufwand in \\(O(N^3)\\)\n\nRotationen und Drehungen sind orthogonale Matrizen \\(Q \\in \\mathbb{R}^{N \\times N}\\) mit\n\n\\(Q Q^{\\top}=I_N, \\ Q^{\\top} Q=I_N\\), so dass \\(Q^{-1}=Q^{\\top}\\),\n\\(|Q v|_2=|v|_2\\) und \\((Q v)^{\\top}(Q w)=v^{\\top} w\\) Längen und Winkel erhaltend,\n\\(\\kappa_2(Q)=1\\).\n\n\n\n\nQR-Zerlegung berechnen",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Direkte Lösungsverfahren für lineare Gleichungen</span>"
    ]
  },
  {
    "objectID": "03-fitting.html",
    "href": "03-fitting.html",
    "title": "3  Lineare Ausgleichsrechnung",
    "section": "",
    "text": "3.1 Normalengleichung",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Lineare Ausgleichsrechnung</span>"
    ]
  },
  {
    "objectID": "appendix.html",
    "href": "appendix.html",
    "title": "Appendix",
    "section": "",
    "text": "Mathematische Grundlagen",
    "crumbs": [
      "Appendix"
    ]
  },
  {
    "objectID": "appendix.html#mathematische-grundlagen",
    "href": "appendix.html#mathematische-grundlagen",
    "title": "Appendix",
    "section": "",
    "text": "Reihen und Summen\n\nAnalysis\nFür alle reellen \\(q \\neq 1\\) und für alle \\(n \\in \\mathbb{N}_0\\) ist:\n\\[\n\\sum_{k=0}^n q^k=\\frac{1-q^{n+1}}{1-q}\n\\]\nDer Grenzwert ist dementsprechend:\n\\[\n\\sum_{k=0}^{\\infty} q^k=\\frac{1}{1-q}\n\\]\n\n\n\nLineare Algebra\n\n\\(2\\times2\\)-Matrix invertieren\n\\[\nA=\\left(\\begin{array}{ll}\na & b \\\\\nc & d\n\\end{array}\\right) \\quad \\text { then } \\quad A^{-1}=\\frac{1}{a d-b c}\\left(\\begin{array}{cc}\nd & -b \\\\\n-c & a\n\\end{array}\\right)\n\\]",
    "crumbs": [
      "Appendix"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referenzen",
    "section": "",
    "text": "Bartels, Sören. 2016. Numerik 3x9: Drei Themengebiete in\njeweils neun kurzen Kapiteln. 1. Aufl. 2016.\nSpringer-Lehrbuch. Berlin Heidelberg: Springer Spektrum. https://doi.org/10.1007/978-3-662-48203-2.\n\n\nWieners, Christian. 2025. “Einführung in Die\nNumerische Mathematik.”",
    "crumbs": [
      "Referenzen"
    ]
  }
]